import logging
import json
import asyncio
from openai import AsyncOpenAI
from typing import Dict
from src.config import OPENROUTER_API_KEY, OPENROUTER_MODEL, SITE_URL, SITE_NAME

logger = logging.getLogger(__name__)

INSTITUTIONAL_SYSTEM_PROMPT = """You are a senior institutional gold futures analyst at a top-tier commodity trading firm. Your reports are read by portfolio managers making million-dollar decisions.

REPORT RULES:
1. Lead with the actionable bias - don't bury the lede
2. Be specific with levels - round numbers matter in Gold
3. Quantify everything - percentages, contracts, sigma levels
4. Flag risks prominently - especially event risk
5. No fluff, no filler - every sentence must add value
6. Use futures terminology: "bid", "offered", "stops", "liquidity pools"
7. Think in terms of positioning: "crowded long", "short squeeze potential"

FORMATTING:
- Use markdown headers and bullets
- Bold key levels and warnings
- Keep it scannable - traders have 30 seconds"""

INSTITUTIONAL_REPORT_TEMPLATE = """Generate a professional institutional Gold Futures (GC) market report using this data:

{market_data}

REQUIRED REPORT STRUCTURE:

# üèÜ GOLD FUTURES INTELLIGENCE BRIEF
**Generated:** [timestamp]
**Bias:** [BULLISH/BEARISH/NEUTRAL] | **Confidence:** [HIGH/MEDIUM/LOW]

---

## ‚ö° EXECUTIVE SUMMARY
- One sentence: What's the play today?
- Primary driver
- Key level to watch

---

## üìä MARKET STRUCTURE
- **VPOC (Volume Point of Control):** [level]
- **Value Area:** [VAH] - [VAL]
- **Regime:** [Trend/Balance/Compressed]
- **Interpretation:** What this means for trade location

---

## üéØ VOLATILITY LEVELS (Sigma Bands)
| Level | Price | Context |
|-------|-------|---------|
| +2œÉ | [price] | Extreme resistance |
| +1œÉ | [price] | Initial resistance |
| **Pivot** | [price] | Current reference |
| -1œÉ | [price] | Initial support |
| -2œÉ | [price] | Extreme support |

**Daily Expected Range:** Based on [X]% annualized vol

---

## üîó MACRO CORRELATIONS
- **DXY (Dollar):** [correlation] - [interpretation]
- **US10Y (Yields):** [correlation] - [interpretation]
- **Divergence Alert:** [any unusual decoupling]

---

## üìà COT POSITIONING (Commitment of Traders)
- **Speculators:** [NET LONG/SHORT] [contracts]
- **Positioning Bias:** [crowded/neutral/light]
- **Smart Money (Commercials):** [what are hedgers doing]
- **Implication:** [contrarian signal or trend confirmation]

---

## üìÖ EVENT RISK
[List upcoming events with impact assessment]
**Risk Warning:** [if applicable]

---

## üé≤ GAME THEORY SCENARIOS

**SCENARIO A - BULL CASE:**
- Trigger: [condition]
- Target: [level]
- Probability: [%]

**SCENARIO B - BEAR CASE:**
- Trigger: [condition]
- Target: [level]
- Probability: [%]

**INVALIDATION:** [level that negates the primary thesis]

---

## üí° BOTTOM LINE
[2-3 sentences max. What should the trader DO with this information?]

---
*Report generated by Gold_Sovereign_AI | Data delayed 15min | Not financial advice*
"""


class ReasoningCore:
    def __init__(self):
        self.client = AsyncOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=OPENROUTER_API_KEY,
            default_headers={
                "HTTP-Referer": SITE_URL,
                "X-Title": SITE_NAME
            }
        ) if OPENROUTER_API_KEY else None

    async def generate_report(self, market_data_dict: Dict) -> str:
        """Generate institutional-grade trading intelligence report."""
        if not self.client:
            logger.error("OpenRouter API key not configured")
            return "# ‚ö†Ô∏è Error: API key not configured"

        user_prompt = INSTITUTIONAL_REPORT_TEMPLATE.format(
            market_data=json.dumps(market_data_dict, indent=2, default=str)
        )

        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = await self.client.chat.completions.create(
                    model=OPENROUTER_MODEL,
                    messages=[
                        {"role": "system", "content": INSTITUTIONAL_SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=2500
                )

                report = response.choices[0].message.content
                return report if report else "# ‚ö†Ô∏è Error: Empty response from LLM"

            except Exception as e:
                if attempt == max_retries - 1:
                    logger.error(f"Error generating report after {max_retries} attempts: {e}")
                    return f"# ‚ö†Ô∏è Error generating report: {str(e)}"
                logger.warning(f"LLM request failed (attempt {attempt + 1}/{max_retries}): {e}. Retrying...")
                await asyncio.sleep(2 * (attempt + 1))
        
        return "# ‚ö†Ô∏è Error: Failed to generate report after retries"
